{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\"><font size=\"3\">\n",
    "Erica Scaduto |\n",
    "Due: May 17, 2020 </font>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\"> <font size=\"5\">**STA 221: Homework 2** \n",
    " </font></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Supervised Learning Basics: 5 points** Answer true or false for each of the question below and give justiﬁcation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Gradient descent is a supervised learning algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Gradient descent is an algorithm to minimize or maximize a function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Logistic regression cannot be performed after linear PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Support vector machine is non-linear classiﬁcation algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) A regression algorithm can be modiﬁed to be used for classiﬁcation as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generative Adversarial Networks (7.5 Points)** In this question, you will be required to read-up certain sections from the following textbook available online at http: //www.deeplearningbook.org and https://arxiv.org/pdf/1701.00160.pdf and answer the following questions in your own words. In your earlier courses, you might have come across maximum likelihood estimation (MLE) technique. To recall, MLE is a way to estimate the parameters of any parametric density. MLE is sometime referred to as explicit generative modeling technique as we have to state the speciﬁc parametric density (for example, Gaussian) that we are using to model the given data. Often times in practice, it becomes hard to pick the right density that ﬁts/models the data at hand. A recent proposal to overcome this issue is the so-called Generative Adversarial Networks (GAN). Here a generative model is developed for the dataset at hand, implicitly. That is, no speciﬁc parametric density is assumed. This technique is called as implicit generative modeling in the literature. In this question, you are required to write a 1-page report on GANs. Speciﬁcally, answer the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Read section 3.13 from http://www.deeplearningbook.org/contents/prob.html. Then deﬁne and interpret Kullback-Leibler (KL) divergence in your own words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b)  Read section 5.5 from http://www.deeplearningbook.org/contents/ml.html. What is the relationship between MLE and KL divergence ? Write in your own words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Collectively summarize the issues with explicit density models from section 2.5 in https://arxiv.org/pdf/1701.00160.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Read section 3.1 and 3.2 on GAN. Explain what is the main idea behind GANs in your own words. Figure 12 is helpful for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) In your own viewpoint, what are three drawbacks with GANs ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Boston Housing Prediction: 7.5 points** In this example, you will work with the Boston Housing Data set. The goal is to predict the median value of housing based on the values of 13 covariates. In the housing train.txt ﬁle, the ﬁrst 13 columns correspond to covariate (X ∈ Rd) and the last column corresponds to median value of housing (Y ∈ R). Assume that they you are using the model\n",
    "\n",
    "Y = β>X = 13 X i=1 Xiβi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433, 13) (433,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "# boston_dataset = load_boston()\n",
    "# column_names = boston_dataset.feature_names\n",
    "housing_train = pd.read_csv('housing_train.txt', sep='\\s+', header=None, index_col=None)\n",
    "X_train = housing_train.iloc[:, 0:13].values\n",
    "y_train = housing_train.iloc[:, 13].values\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Use linear regression on housing train.txt to estimate β (do not use housing test.txt). Calculate the mean square prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.58432121803993"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression().fit(X_train, y_train)\n",
    "reg.intercept_\n",
    "#Calculate the mean-square prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)  Now use housing test.txt (note that this data was not used when estimating β) and the estimate for β from above to predict the housing prices in the test dataset. Calculate the mean-square prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(74, 13) (74,)\n"
     ]
    }
   ],
   "source": [
    "housing_test = pd.read_csv('housing_test.txt', sep='\\s+', header=None, index_col=None)\n",
    "X_test = housing_test.iloc[:, 0:13].values\n",
    "y_test = housing_test.iloc[:, 13].values\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.49370175397718"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_test, y_test)\n",
    "reg.intercept_\n",
    "# Calculate the mean-square prediction error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Change the model in Question 3, to\n",
    "\n",
    "and repeat the same process in question 3. Note that this could still be considered as a linear model with data ˜ X = [X1,X2,...,X13,X2 1,X1X2,...,X2 13]. Does it give any improvement (in terms of mean squared prediction error) compared to the previous model from question 3 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amazon Review Classiﬁcation: 10 points** In this question, we will take use the preprocessed Amazon review data from HW2 (in both Document-Term matrix and TF-IDF matrix representation format) to do classiﬁcation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['dat'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       My husband and I selected the Diaper \"Champ\" m...\n",
       "1       I have had a diaper genie for almost 4 years s...\n",
       "2       We loved this pail at first. The mechanism see...\n",
       "3       Bad construction is my main issue. My husband ...\n",
       "4       Diaper catches and jams in the well and that i...\n",
       "                              ...                        \n",
       "1307    Got this for a gift, not too expensive and the...\n",
       "1308    Our previous Sony monitor\\'s speaker unit was ...\n",
       "1309    Don\\'t waste your money on cheaper models. The...\n",
       "1310    I bought this monitor for my third child.  I h...\n",
       "1311    I went ahead and purchased the Sony Baby Call ...\n",
       "Name: review, Length: 1312, dtype: category\n",
       "Categories (1307, object): [, \"Sophie the Giraffe\" has tested positive for p..., \"This gate expands from 29 to 52\".  This is to..., (This is a long review, but if you read the wh..., ..., we are constantly having troubles with getting..., we bought it from amazon and had used it for o..., we bought this swing thinking that it would be..., we love so pie, she is so cute. my baby loves ...]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conda install pyreadr \n",
    "import pyreadr\n",
    "data = pyreadr.read_r('Amazon.rdata')\n",
    "print(data.keys()) \n",
    "amazonData = data['dat']\n",
    "amazonData['review'] # access only review column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from nltk.stem.snowball import EnglishStemmer \n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\") # changed to english based on review language\n",
    "analyzer = CountVectorizer().build_analyzer() \n",
    "\n",
    "def stemmed_words(doc): \n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "output = stemmed_words(df1.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>08</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>10oz</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>...</th>\n",
       "      <th>yum</th>\n",
       "      <th>yup</th>\n",
       "      <th>yuppi</th>\n",
       "      <th>zantac</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zola</th>\n",
       "      <th>zoli</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  08  09  10  100  1000  10oz  10x  11  ...  yum  yup  yuppi  \\\n",
       "0   0    0   0   0   0    0     0     0    0   0  ...    0    0      0   \n",
       "1   0    0   0   0   0    0     0     0    0   0  ...    0    0      0   \n",
       "2   0    0   0   0   0    0     0     0    0   0  ...    0    0      0   \n",
       "3   0    0   0   0   0    0     0     0    0   0  ...    0    0      0   \n",
       "4   0    0   0   0   0    1     0     0    0   0  ...    0    0      0   \n",
       "\n",
       "   zantac  zero  zip  zola  zoli  zoo  zoom  \n",
       "0       0     0    0     0     0    0     0  \n",
       "1       0     0    0     0     0    0     0  \n",
       "2       0     0    0     0     0    0     0  \n",
       "3       0     0    0     0     0    0     0  \n",
       "4       0     0    0     0     0    0     0  \n",
       "\n",
       "[5 rows x 4137 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# DocTermMatrix \n",
    "stem_vectorizer = CountVectorizer(analyzer=stemmed_words)\n",
    "DocTerm = stem_vectorizer.fit_transform(amazonData['review'])\n",
    "DTDF = pd.DataFrame(DocTerm.toarray(), columns=stem_vectorizer.get_feature_names())\n",
    "DocTermMatrix = DTDF.values\n",
    "DTDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absolutly</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absorbing</th>\n",
       "      <th>absorbs</th>\n",
       "      <th>...</th>\n",
       "      <th>yup</th>\n",
       "      <th>yuppie</th>\n",
       "      <th>zantac</th>\n",
       "      <th>zero</th>\n",
       "      <th>zip</th>\n",
       "      <th>zola</th>\n",
       "      <th>zoli</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.02966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075259</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5806 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ability      able    about  above  absolute  absolutely  absolutly  absorb  \\\n",
       "0      0.0  0.000000  0.02966    0.0       0.0         0.0        0.0     0.0   \n",
       "1      0.0  0.075259  0.00000    0.0       0.0         0.0        0.0     0.0   \n",
       "2      0.0  0.000000  0.00000    0.0       0.0         0.0        0.0     0.0   \n",
       "3      0.0  0.000000  0.00000    0.0       0.0         0.0        0.0     0.0   \n",
       "4      0.0  0.000000  0.00000    0.0       0.0         0.0        0.0     0.0   \n",
       "\n",
       "   absorbing  absorbs  ...  yup  yuppie  zantac  zero  zip  zola  zoli  zoo  \\\n",
       "0        0.0      0.0  ...  0.0     0.0     0.0   0.0  0.0   0.0   0.0  0.0   \n",
       "1        0.0      0.0  ...  0.0     0.0     0.0   0.0  0.0   0.0   0.0  0.0   \n",
       "2        0.0      0.0  ...  0.0     0.0     0.0   0.0  0.0   0.0   0.0  0.0   \n",
       "3        0.0      0.0  ...  0.0     0.0     0.0   0.0  0.0   0.0   0.0  0.0   \n",
       "4        0.0      0.0  ...  0.0     0.0     0.0   0.0  0.0   0.0   0.0  0.0   \n",
       "\n",
       "   zoom  zooms  \n",
       "0   0.0    0.0  \n",
       "1   0.0    0.0  \n",
       "2   0.0    0.0  \n",
       "3   0.0    0.0  \n",
       "4   0.0    0.0  \n",
       "\n",
       "[5 rows x 5806 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF-IDF matrix  \n",
    "vectorizer = TfidfVectorizer(token_pattern='[a-z]{3,15}') # initiate TF-IDF vectorizer w/ token pattern \n",
    "Tfid = vectorizer.fit_transform(amazonData['review']) \n",
    "TfDF = pd.DataFrame(Tfid.toarray(), columns=vectorizer.get_feature_names())\n",
    "TfidMatrix = TfDF.values\n",
    "TfDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) How many reviews of each rating value are there in the entire dataset?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of reviews:  1312\n",
      "Number of unique rating values:  2\n",
      "There are 656 number of reviews with rating value of '1'\n",
      "There are 656 number of reviews with rating value of '5'\n"
     ]
    }
   ],
   "source": [
    "print(\"Total # of reviews: \", len(amazonData['rating']))\n",
    "print(\"Number of unique rating values: \", len(amazonData['rating'].unique())) # How many rating values are present in the dataset ?\n",
    "\n",
    "# How many reviews of each rating value are there in the entire dataset? \n",
    "print(\"There are {} number of reviews with rating value of '1'\".format(str(len(df1[amazonData['rating'] == 1]))))\n",
    "print(\"There are {} number of reviews with rating value of '5'\".format(str(len(df1[amazonData['rating'] == 5]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our goal is to build a classiﬁer that reads the review and classiﬁes whether the review was ”good” (rating = 5) or ”bad” (rating = 1). What is the best performance of a ”constant classiﬁer”, a classiﬁer that ignores the review and blindly assigns a constant classiﬁcation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFID constant classifier score: 0.5\n",
      "DocTerm constant classifier score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# Constant Classifier \n",
    "import numpy as np\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "DT_clf = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "DT_clf.fit(DocTermMatrix, amazonData['rating'])\n",
    "DT_clf.predict(DocTermMatrix)\n",
    "DT_score = DT_clf.score(DocTermMatrix, amazonData['rating'])\n",
    "\n",
    "TF_clf = DummyClassifier(strategy=\"constant\", constant=5)\n",
    "TF_clf.fit(TfidMatrix, amazonData['rating'])\n",
    "TF_clf.predict(TfidMatrix)\n",
    "TF_score = TF_clf.score(TfidMatrix, amazonData['rating'])\n",
    "print(\"TFID constant classifier score: {}\".format(str(TF_score)))\n",
    "print(\"DocTerm constant classifier score: {}\".format(str(DT_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Now we’ll run L1-regularized logistic regression on our dataset. Split the data into two parts: the training set (which is 70%) and testing set (which is the rest). Fit a L1-regularized logistic regression model by letting python chose the regularization parameter itself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of each feature: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Training accuracy: 0.9945533769063181\n"
     ]
    }
   ],
   "source": [
    "X = DocTermMatrix\n",
    "y = amazonData['rating']\n",
    "# Split the data into test and training sets, with 30% of samples being put into the test set\n",
    "DT_X_train, DT_X_test, DT_y_train, DT_y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "dt_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "dt_clf.fit(DT_X_train, DT_y_train)\n",
    "print('Coefficient of each feature:', dt_clf.coef_)\n",
    "print('Training accuracy:', clf.score(DT_X_train, DT_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient of each feature: [[0. 0. 0. ... 0. 0. 0.]]\n",
      "Training accuracy: 0.8921568627450981\n"
     ]
    }
   ],
   "source": [
    "X = TfidMatrix\n",
    "y = amazonData['rating']\n",
    "# Split the data into test and training sets, with 30% of samples being put into the test set\n",
    "TF_X_train, TF_X_test, TF_y_train, TF_y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "tf_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "tf_clf.fit(TF_X_train, TF_y_train)\n",
    "print('Coefficient of each feature:', tf_clf.coef_)\n",
    "print('Training accuracy:', tf_clf.score(TF_X_train, TF_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) How many covariates have non-zero coeﬃcients in the model selected by python ? List the twenty words with the most positive coeﬃcients and twenty words with most negative coeﬃcients.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 73 covariates with non-zeo coefficients for DocumentTerm \n",
      "\n",
      "The 20 Top most positive coefficient for DocumentTerm are: ['love', 'voic', 'teeth', 'great', 'those', 'soni', 'chew', 'gift', 'bath', 'easi', 'hear', 'recommend', 'sophi', 'perfect', 'grab', 'happi', 'well', 'wonder', 'other', 'pregnant'] \n",
      "\n",
      "The 20 Top most negative coefficient for DocumentTerm are: ['return', 'wast', 'four', 'won', 'less', 'until', 'not', 'stop', 'usual', 'diaper', 'them', 'review', 'after', 'useless', 'becaus', 'disappoint', 'gate', 'leak', 'husband', 'back']\n"
     ]
    }
   ],
   "source": [
    "# Document Term \n",
    "DT_coef = pd.DataFrame()\n",
    "DT_coef['Word'] = stem_vectorizer.get_feature_names()\n",
    "DT_coef['Coef'] = dt_clf.coef_.tolist()[0]\n",
    "positive_coef = DT_coef[DT_coef['Coef'] > 0]\n",
    "print(\"There are {} covariates with non-zeo coefficients for DocumentTerm \\n\".format(len(positive_coef)))\n",
    "pos20 = DT_coef.sort_values(by='Coef', ascending=False)[:20]\n",
    "print(\"The 20 Top most positive coefficient for DocumentTerm are: {} \\n\".format(pos20['Word'].tolist()))\n",
    "neg20 = DT_coef.sort_values(by='Coef', ascending=True)[:20]\n",
    "print(\"The 20 Top most negative coefficient for DocumentTerm are: {}\".format(neg20['Word'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 covariates with non-zeo coefficients for TFID \n",
      "\n",
      "The 20 Top most positive coefficient for TFID are: ['loves', 'love', 'sophie', 'teething', 'teether', 'great', 'loved', 'she', 'little', 'easy', 'toy', 'voice', 'gift', 'his', 'chew', 'sony', 'monitor', 'hear', 'static', 'her'] \n",
      "\n",
      "The 20 Top most negative coefficient for TFID are: ['not', 'after', 'diaper', 'waste', 'the', 'bottles', 'back', 'you', 'they', 'work', 'unit', 'was', 'gate', 'cup', 'stopped', 'returned', 'return', 'doesn', 'out', 'receievers']\n"
     ]
    }
   ],
   "source": [
    "# TFID \n",
    "TFID_coef = pd.DataFrame()\n",
    "TFID_coef['Word'] = vectorizer.get_feature_names()\n",
    "TFID_coef['Coef'] = tf_clf.coef_.tolist()[0]\n",
    "positive_coef = TFID_coef[TFID_coef['Coef'] > 0]\n",
    "print(\"There are {} covariates with non-zeo coefficients for TFID \\n\".format(len(positive_coef)))\n",
    "pos20 = TFID_coef.sort_values(by='Coef', ascending=False)[:20]\n",
    "print(\"The 20 Top most positive coefficient for TFID are: {} \\n\".format(pos20['Word'].tolist()))\n",
    "neg20 = TFID_coef.sort_values(by='Coef', ascending=True)[:20]\n",
    "print(\"The 20 Top most negative coefficient for TFID are: {}\".format(neg20['Word'].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Now run the ﬁtted logisitic model on your testing data and report the misclassiﬁcation rate.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.8959390862944162\n",
      "Misclassification of 'BAD':  0.16751269035532995\n",
      "Misclassification of 'GOOD':  0.04060913705583756\n",
      "Total Misclassification Rate':  0.10406091370558376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "TF_y_pred = tf_clf.predict(TF_X_test)\n",
    "print('Training accuracy:', tf_clf.score(TF_X_test, TF_y_test))\n",
    "tf_cm = confusion_matrix(TF_y_test, TF_y_pred, labels = [1,5])\n",
    "\n",
    "print(\"Misclassification of 'BAD': \", tf_cm[1][0] / sum(tf_cm[1]))\n",
    "print(\"Misclassification of 'GOOD': \", tf_cm[0][1] / sum(tf_cm[0]))\n",
    "print(\"Total Misclassification Rate': \", (tf_cm[0][1] + tf_cm[1][0])  / (sum(tf_cm[0]) + sum(tf_cm[1])))\n",
    "\n",
    "# 1-clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9086294416243654\n",
      "Misclassification of 'BAD':  0.09644670050761421\n",
      "Misclassification of 'GOOD':  0.08629441624365482\n",
      "Total Misclassification Rate':  0.09137055837563451\n"
     ]
    }
   ],
   "source": [
    "DT_y_pred = dt_clf.predict(DT_X_test)\n",
    "print('Training accuracy:', dt_clf.score(DT_X_test, DT_y_test))\n",
    "dt_cm = confusion_matrix(DT_y_test,DT_y_pred, labels = [1,5])\n",
    "\n",
    "print(\"Misclassification of 'BAD': \", dt_cm[1][0] / sum(dt_cm[1]))\n",
    "print(\"Misclassification of 'GOOD': \", dt_cm[0][1] / sum(dt_cm[0]))\n",
    "print(\"Total Misclassification Rate': \", (dt_cm[0][1] + dt_cm[1][0])  / (sum(dt_cm[0]) + sum(dt_cm[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189   8]\n",
      " [ 33 164]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf_cm)\n",
    "labels = ['bad', 'good']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(tf_cm)\n",
    "plt.title('TFID: Confusion matrix')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[180  17]\n",
      " [ 19 178]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dt_cm)\n",
    "labels = ['bad', 'good']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(dt_cm)\n",
    "plt.title('DocuTerm: Confusion matrix')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does this compare with the “constant classiﬁer” we originally discussed before (i.e., is it better or worse)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
